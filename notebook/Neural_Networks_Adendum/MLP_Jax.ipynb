{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f905b6b6-eb3e-4014-b412-7d6a4a7c084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax_metrics as jm\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from functools import partial\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fc635af-64be-4e89-8755-af4dd5b8b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \"\"\"\n",
    "    We have a basic netwrk implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, network_params):\n",
    "        layers, step_size, epochs, batch, n_targets = network_params\n",
    "        self.layer_sizes = layers\n",
    "        self.step_size = step_size\n",
    "        self.num_epochs = epochs\n",
    "        self.batch_size = batch\n",
    "        self.n_targets = n_targets\n",
    "        self.params = self._init_network_params(self.layer_sizes, random.PRNGKey(0))\n",
    "        self.batched_predict = vmap(self.predict, in_axes=(None, 0))\n",
    "\n",
    "    @staticmethod\n",
    "    def _random_layer_params(m, n, key, scale=1e-2):\n",
    "        w_key, b_key = random.split(key)\n",
    "        return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "    # Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "    def _init_network_params(self, sizes, key):\n",
    "        keys = random.split(key, len(sizes))\n",
    "        return [self._random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return jnp.maximum(0, x)\n",
    "\n",
    "    def predict(self, params, image):\n",
    "        # Layer calculations using \n",
    "        # [Layer1, Layer2, Layer3] = [:-1]\n",
    "        activations = image\n",
    "        for w, b in params[:-1]:\n",
    "            outputs = jnp.dot(w, activations) + b\n",
    "            activations = self.relu(outputs)\n",
    "        # Output Layer\n",
    "        final_w, final_b = params[-1]\n",
    "        logits = jnp.dot(final_w, activations) + final_b\n",
    "        return jax.nn.softmax(logits)\n",
    "    \n",
    "    def batch_predict(self, params, batched_images):\n",
    "        return self.batched_predict(params, batched_images)\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot(x, k, dtype=jnp.float32):\n",
    "        \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "        return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "    \n",
    "    def accuracy(self, images, targets):\n",
    "        target_class = jnp.argmax(targets, axis=1)\n",
    "        predicted_class = jnp.argmax(self.batched_predict(self.params, images), axis=1)\n",
    "        return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "    def loss(self, params, images, targets):\n",
    "        preds = self.batched_predict(params, images)\n",
    "        return jnp.mean(jm.losses.crossentropy(preds, targets))\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def update(self, params, x, y):\n",
    "        grads = grad(self.loss)(params, x, y)\n",
    "        return [(w - self.step_size * dw, b - self.step_size * db)\n",
    "                      for (w, b), (dw, db) in zip(params, grads)] \n",
    "    \n",
    "    #@partial(jit, static_argnums=(0,))\n",
    "    def dloss(self, params, x, y):\n",
    "        return grad(self.loss)(params, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a419e27-3989-49a1-afbf-450e8295b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [784, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "network_params = (layer_sizes, step_size, num_epochs, batch_size, n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22d6e780-e785-4799-b12b-654f16514b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91180455-0a42-4859-bca9-342e5332a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "import tensorflow_datasets as tfds\n",
    "data_dir = '/home/remote_code/Jax_Excercises/tfds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a4d98e6-7e03-4d2d-80f8-1ba61cd1db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data['train'], mnist_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7965463-c873-45b8-b441-58cdd7200683",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19ea62eb-ff75-4080-82ce-fe3c096d8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = train_data['image'], train_data['label']\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "train_labels = network.one_hot(train_labels, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d34dc070-ecf8-4097-ac6e-2f6b269182b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = test_data['image'], test_data['label']\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))\n",
    "test_labels = network.one_hot(test_labels, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0788e77-3d53-44b9-9776-ed4a8011e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_train_batches():\n",
    "    # as_supervised=True gives us the (image, label) as a tuple instead of a dict\n",
    "    ds = tfds.load(name='mnist', split='train', as_supervised=True, data_dir=data_dir)\n",
    "    # You can build up an arbitrary tf.data input pipeline\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    # tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays\n",
    "    return tfds.as_numpy(ds)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for x, y in get_train_batches():\n",
    "        x = x.astype(jnp.float32)\n",
    "        x = jnp.reshape(x, (len(x), num_pixels))\n",
    "        y = network.one_hot(y, num_labels)\n",
    "        network.params = network.update(network.params, x, y)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    train_acc = network.accuracy(train_images, train_labels)\n",
    "    test_acc = network.accuracy(test_images, test_labels)\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    print(\"Training set accuracy {}\".format(train_acc))\n",
    "    print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd832960-1a10-4148-bdf6-6f905bec106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.6497804e-20, 2.5545521e-24, 1.5067530e-13, 3.7225091e-11,\n",
       "       1.6700621e-27, 1.5232610e-21, 2.0894807e-30, 1.0000000e+00,\n",
       "       7.8525401e-22, 3.5597523e-16], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(network.params, x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afa1fbf0-e72e-4199-b41d-eae81602e26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce229c8-abb0-4e3c-b4e6-f4c6ff1d24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jax.xla_computation(network.dloss)(network.params, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21e23c05-2b12-4c7b-97de-ce6672c2a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"t.dot\", \"w\") as f:\n",
    "    f.write(z.as_hlo_dot_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f459390-db57-4cf6-aa1c-1740b83855f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
